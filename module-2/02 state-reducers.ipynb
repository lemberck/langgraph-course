{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36b496da",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-2/state-reducers.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239428-lesson-2-state-reducers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ae0ff7-497d-4c31-a57a-00fe92799232",
   "metadata": {},
   "source": [
    "# State Reducers \n",
    "\n",
    "## Review\n",
    "\n",
    "We covered a few different ways to define LangGraph state schema, including `TypedDict`, `Pydantic`, or `Dataclasses`.\n",
    " \n",
    "## Goals\n",
    "\n",
    "Now, we're going to dive into reducers, which specify how state updates are performed on specific keys / channels in the state schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "398c5e8e-641f-4be6-b1e8-7531f86bd2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langchain_core langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5bd534-c5be-48fe-91bc-af39ebee76b7",
   "metadata": {},
   "source": [
    "## Default overwriting state\n",
    "\n",
    "Let's use a `TypedDict` as our state schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67e27925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyppeteer in /home/lemberck/Desktop/langchain Academy/langchain-academy/lc-academy-env/lib/python3.12/site-packages (2.0.0)\n",
      "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in /home/lemberck/Desktop/langchain Academy/langchain-academy/lc-academy-env/lib/python3.12/site-packages (from pyppeteer) (1.4.4)\n",
      "Requirement already satisfied: certifi>=2023 in /home/lemberck/Desktop/langchain Academy/langchain-academy/lc-academy-env/lib/python3.12/site-packages (from pyppeteer) (2025.8.3)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in /home/lemberck/Desktop/langchain Academy/langchain-academy/lc-academy-env/lib/python3.12/site-packages (from pyppeteer) (8.7.0)\n",
      "Requirement already satisfied: pyee<12.0.0,>=11.0.0 in /home/lemberck/Desktop/langchain Academy/langchain-academy/lc-academy-env/lib/python3.12/site-packages (from pyppeteer) (11.1.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /home/lemberck/Desktop/langchain Academy/langchain-academy/lc-academy-env/lib/python3.12/site-packages (from pyppeteer) (4.67.1)\n",
      "Requirement already satisfied: urllib3<2.0.0,>=1.25.8 in /home/lemberck/Desktop/langchain Academy/langchain-academy/lc-academy-env/lib/python3.12/site-packages (from pyppeteer) (1.26.20)\n",
      "Requirement already satisfied: websockets<11.0,>=10.0 in /home/lemberck/Desktop/langchain Academy/langchain-academy/lc-academy-env/lib/python3.12/site-packages (from pyppeteer) (10.4)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/lemberck/Desktop/langchain Academy/langchain-academy/lc-academy-env/lib/python3.12/site-packages (from importlib-metadata>=1.4->pyppeteer) (3.23.0)\n",
      "Requirement already satisfied: typing-extensions in /home/lemberck/Desktop/langchain Academy/langchain-academy/lc-academy-env/lib/python3.12/site-packages (from pyee<12.0.0,>=11.0.0->pyppeteer) (4.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyppeteer # alternative local mermaid draw method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e2438c-9353-4256-bc3c-1bb830374c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "class State(TypedDict):\n",
    "    foo: int\n",
    "\n",
    "def node_1(state):\n",
    "    print(\"---Node 1---\")\n",
    "    return {\"foo\": state['foo'] + 1} # STATE UPDATE !!\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"node_1\", node_1)\n",
    "\n",
    "# Logic\n",
    "builder.add_edge(START, \"node_1\")\n",
    "builder.add_edge(\"node_1\", END)\n",
    "\n",
    "# Add\n",
    "graph = builder.compile()\n",
    "\n",
    "# View - I was getting 500 error when running this - mermaid API was down\n",
    "# display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69634df1-4f02-446f-b5cf-6a83d1e15e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Node 1---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'foo': 2}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"foo\" : 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775a099c-c41c-412f-8f05-e7436388ae79",
   "metadata": {},
   "source": [
    "Let's look at the state update, `return {\"foo\": state['foo'] + 1}`.\n",
    "\n",
    "As discussed before, **by default** LangGraph doesn't know the preferred way to update the state.\n",
    " \n",
    "#### So, Langgraph will just overwrite the value of `foo` in `node_1`: \n",
    "\n",
    "```\n",
    "return {\"foo\": state['foo'] + 1}\n",
    "```\n",
    " \n",
    "If we pass `{'foo': 1}` as input, the state returned from the graph is `{'foo': 2}`.\n",
    "\n",
    "## Branching\n",
    "\n",
    "Let's look at a case where our nodes branch (execute in parallel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8d6ad4-2991-4325-933d-67057bc150f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    foo: int\n",
    "\n",
    "def node_1(state):\n",
    "    print(\"---Node 1---\")\n",
    "    return {\"foo\": state['foo'] + 1}\n",
    "\n",
    "def node_2(state):\n",
    "    print(\"---Node 2---\")\n",
    "    return {\"foo\": state['foo'] + 1}\n",
    "\n",
    "def node_3(state):\n",
    "    print(\"---Node 3---\")\n",
    "    return {\"foo\": state['foo'] + 1}\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"node_1\", node_1)\n",
    "builder.add_node(\"node_2\", node_2)\n",
    "builder.add_node(\"node_3\", node_3)\n",
    "\n",
    "# Logic\n",
    "builder.add_edge(START, \"node_1\")\n",
    "builder.add_edge(\"node_1\", \"node_2\") # branch node1 > node2 (not a conditional edge)\n",
    "builder.add_edge(\"node_1\", \"node_3\") # branch node1 > node3 (not a conditional edge)\n",
    "builder.add_edge(\"node_2\", END)\n",
    "builder.add_edge(\"node_3\", END)\n",
    "\n",
    "# Add\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "#display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106729b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Node 1---\n",
      "---Node 2---\n",
      "---Node 3---\n",
      "InvalidUpdateError occurred: At key 'foo': Can receive only one value per step. Use an Annotated key to handle multiple values.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_CONCURRENT_GRAPH_UPDATE\n"
     ]
    }
   ],
   "source": [
    "from langgraph.errors import InvalidUpdateError # to catch the error\n",
    "try:\n",
    "    graph.invoke({\"foo\" : 1})\n",
    "except InvalidUpdateError as e:\n",
    "    print(f\"InvalidUpdateError occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9717ccd-3d34-476a-8952-e6a7629ebefe",
   "metadata": {},
   "source": [
    "We see a problem! \n",
    "\n",
    "Node 1 branches to nodes 2 and 3.\n",
    "\n",
    "Nodes 2 and 3 run in parallel, which means they run in the same step of the graph.\n",
    "\n",
    "#### They both attempt to overwrite the state *within the same step*. \n",
    "\n",
    "#### This is ambiguous for the graph! Which state should it keep? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1609cf7-dc47-4926-a154-77904b6cc550",
   "metadata": {},
   "source": [
    "## Reducers\n",
    "\n",
    "[Reducers](https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers) give us a general way to address this problem.\n",
    "\n",
    "They allow to specify how to perform updates.\n",
    "\n",
    "We can use the `Annotated` type to specify a reducer function. \n",
    "\n",
    "For example, in this case let's append the value returned from each node rather than overwriting them.\n",
    "\n",
    "We just need a reducer that can perform this: `operator.add` is a function from Python's built-in operator module.\n",
    "\n",
    "When `operator.add` is applied to lists, it performs list concatenation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103d808c-55ec-44f2-a688-7b5e1572875a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add\n",
    "from typing import Annotated\n",
    "\n",
    "class State(TypedDict):\n",
    "    foo: Annotated[list[int], add] # 'add' is the reducer function that will tell the graph how to update the state\n",
    "\n",
    "def node_1(state):\n",
    "    print(\"---Node 1---\")\n",
    "    return {\"foo\": [state['foo'][0] + 1]}\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"node_1\", node_1)\n",
    "\n",
    "# Logic\n",
    "builder.add_edge(START, \"node_1\")\n",
    "builder.add_edge(\"node_1\", END)\n",
    "\n",
    "# Add\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "#display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e68cdff-f6e1-4de5-a7bf-6ca0cfee19bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Node 1---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'foo': [1, 2]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"foo\" : [1]})\n",
    "\n",
    "# result: {'foo': [1, 2]} -> the value is not overwritten, it is appended to the list of ints.\n",
    "# 1 is the initial value of the list, 2 is the value returned by node_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fbd6e0-0207-4049-b86d-c006cbba630b",
   "metadata": {},
   "source": [
    "Now, our state key `foo` is a list.\n",
    "\n",
    "This `operator.add` reducer function will append updates from each node to this list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "768fd0ed-5e24-44a4-b14d-0e299310e105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_1(state):\n",
    "    print(\"---Node 1---\")\n",
    "    return {\"foo\": [state['foo'][-1] + 1]}\n",
    "\n",
    "def node_2(state):\n",
    "    print(\"---Node 2---\")\n",
    "    return {\"foo\": [state['foo'][-1] + 1]}\n",
    "\n",
    "def node_3(state):\n",
    "    print(\"---Node 3---\")\n",
    "    return {\"foo\": [state['foo'][-1] + 1]}\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"node_1\", node_1)\n",
    "builder.add_node(\"node_2\", node_2)\n",
    "builder.add_node(\"node_3\", node_3)\n",
    "\n",
    "# Logic\n",
    "builder.add_edge(START, \"node_1\")\n",
    "builder.add_edge(\"node_1\", \"node_2\") #branch 1\n",
    "builder.add_edge(\"node_1\", \"node_3\") #branch 2\n",
    "builder.add_edge(\"node_2\", END)\n",
    "builder.add_edge(\"node_3\", END)\n",
    "\n",
    "# Add\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "#display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5439baad-5a75-4188-b936-dbe74cdd9078",
   "metadata": {},
   "source": [
    "We can see that updates in nodes 2 and 3 are performed concurrently because they are in the same step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44598f97-0a59-4ed4-9d9a-e15a98b3d8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Node 1---\n",
      "---Node 2---\n",
      "---Node 3---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'foo': [1, 2, 3, 3]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"foo\" : [1]})\n",
    "# result: {'foo': [1, 2, 3, 3]}\n",
    "# 1 is the initial value of the list, 2 is the value returned by node_1, 3 is the value returned by node_2, 3 is the value returned by node_3,\n",
    "# as node_2 returns 3, node_3 returns 3 in parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87faaa07-2955-4466-9bca-4b536e05f260",
   "metadata": {},
   "source": [
    "Now, let's see what happens if we pass `None` to `foo`.\n",
    "\n",
    "#### We see an error because our reducer, `operator.add`, attempts to concatenate `NoneType` pass as input to list in `node_1`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f05984b-2bc7-48d1-b070-c8a001a6b59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TypeError occurred: can only concatenate list (not \"NoneType\") to list\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    graph.invoke({\"foo\" : None})\n",
    "except TypeError as e:\n",
    "    print(f\"TypeError occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9d4930-ee8f-4ffc-b9e1-3c910b2e15f6",
   "metadata": {},
   "source": [
    "## Custom Reducers\n",
    "\n",
    "To address cases like this, [we can also define custom reducers](https://langchain-ai.github.io/langgraph/how-tos/subgraph/#custom-reducer-functions-to-manage-state). \n",
    "\n",
    "For example, lets define custom reducer logic to combine lists and handle cases where either or both of the inputs might be `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3314219d-29ff-4b78-b18e-fa9f7878a02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_list(left: list | None, right: list | None) -> list:\n",
    "    \"\"\"Safely combine two lists, handling cases where either or both inputs might be None.\n",
    "\n",
    "    Args:\n",
    "        left (list | None): The first list to combine, or None.\n",
    "        right (list | None): The second list to combine, or None.\n",
    "\n",
    "    Returns:\n",
    "        list: A new list containing all elements from both input lists.\n",
    "               If an input is None, it's treated as an empty list.\n",
    "    \"\"\"\n",
    "    if not left:\n",
    "        left = []\n",
    "    if not right:\n",
    "        right = []\n",
    "    return left + right\n",
    "\n",
    "class DefaultState(TypedDict):\n",
    "    foo: Annotated[list[int], add]\n",
    "\n",
    "class CustomReducerState(TypedDict):\n",
    "    foo: Annotated[list[int], reduce_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdea26a-38d0-4faf-9bf6-cd52eb902635",
   "metadata": {},
   "source": [
    "In `node_1`, we append the value 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f270db-6eff-47c9-853b-dfb8108ff28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TypeError occurred: can only concatenate list (not \"NoneType\") to list\n"
     ]
    }
   ],
   "source": [
    "def node_1(state):\n",
    "    print(\"---Node 1---\")\n",
    "    return {\"foo\": [2]} # append 2 to foo\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(DefaultState) # Using default reducer - will get error!\n",
    "builder.add_node(\"node_1\", node_1)\n",
    "\n",
    "# Logic\n",
    "builder.add_edge(START, \"node_1\")\n",
    "builder.add_edge(\"node_1\", END)\n",
    "\n",
    "# Add\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "#display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "\n",
    "try:\n",
    "    print(graph.invoke({\"foo\" : None})) # passing None to foo will raise error due to default reducer\n",
    "except TypeError as e:\n",
    "    print(f\"TypeError occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd21936b-62f1-4311-9ce5-2c7d08aa35bf",
   "metadata": {},
   "source": [
    "Now, try with our custom reducer. We can see that no error is thrown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867784bc-796c-4b1e-a4d3-2810395cf5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Node 1---\n",
      "{'foo': [2]}\n"
     ]
    }
   ],
   "source": [
    "# Build graph\n",
    "builder = StateGraph(CustomReducerState) # Using custom reducer - solves the problem!\n",
    "builder.add_node(\"node_1\", node_1)\n",
    "\n",
    "# Logic\n",
    "builder.add_edge(START, \"node_1\")\n",
    "builder.add_edge(\"node_1\", END)\n",
    "\n",
    "# Add\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "#display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "\n",
    "try:\n",
    "    print(graph.invoke({\"foo\" : None})) # passing None to foo will NOT raise error due to custom reducer\n",
    "except TypeError as e:\n",
    "    print(f\"TypeError occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ebc65e-c185-4981-a6e7-20fe37d2f8fe",
   "metadata": {},
   "source": [
    "## Messages\n",
    "\n",
    "In module 1, we showed how to use a built-in reducer, `add_messages`, to handle messages in state.\n",
    "\n",
    "We also showed that [`MessagesState` is a useful shortcut if you want to work with messages](https://langchain-ai.github.io/langgraph/concepts/low_level/#messagesstate). \n",
    "\n",
    "* `MessagesState` has a built-in `messages` key \n",
    "* It also has a built-in `add_messages` reducer for this key\n",
    "\n",
    "These two are equivalent. \n",
    "\n",
    "We'll use the `MessagesState` class via `from langgraph.graph import MessagesState` for brevity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "901e69e5-c4cb-4d58-82fb-3b7d968758e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langgraph.graph import MessagesState\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# Define a custom TypedDict that includes a list of messages with add_messages reducer\n",
    "class CustomMessagesState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    added_key_1: str\n",
    "    added_key_2: str\n",
    "    # etc\n",
    "\n",
    "# Use MessagesState, which includes the messages key with add_messages reducer\n",
    "# This is equivalent to the previous CustomMessagesState\n",
    "class ExtendedMessagesState(MessagesState):\n",
    "    # Add any keys needed beyond messages, which is pre-built \n",
    "    added_key_1: str\n",
    "    added_key_2: str\n",
    "    # etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287805e4-722a-4428-b040-2892b29de870",
   "metadata": {},
   "source": [
    "Let's talk a bit more about usage of the `add_messages` reducer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f61350-4fe0-4a2b-bb24-9305afb3c668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Hello! How can I assist you?', additional_kwargs={}, response_metadata={}, name='Model', id='72ccc257-2be1-49d5-97da-3b9caa18b6fb'),\n",
       " HumanMessage(content=\"I'm looking for information on marine biology.\", additional_kwargs={}, response_metadata={}, name='Lance', id='37146937-8394-4314-9ebb-fcfec7fb712f'),\n",
       " AIMessage(content='Sure, I can help with that. What specifically are you interested in?', additional_kwargs={}, response_metadata={}, name='Model', id='64856c34-0d25-4e00-a011-ce6c4738a362')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph.message import add_messages # message reducer\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "# Initial state\n",
    "initial_messages = [AIMessage(content=\"Hello! How can I assist you?\", name=\"Model\"),\n",
    "                    HumanMessage(content=\"I'm looking for information on marine biology.\", name=\"Lance\")\n",
    "                   ]\n",
    "\n",
    "# New message to add\n",
    "new_message = AIMessage(content=\"Sure, I can help with that. What specifically are you interested in?\", name=\"Model\")\n",
    "\n",
    "# Test\n",
    "add_messages(initial_messages , new_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc492370-0502-43e6-87cc-181c60b3dbdb",
   "metadata": {},
   "source": [
    "So we can see that `add_messages` allows us to append messages to the `messages` key in our state.\n",
    "\n",
    "### Re-writing\n",
    "\n",
    "Let's show some useful tricks when working with the `add_messages` reducer.\n",
    "\n",
    "##### If we pass a message with the same ID as an existing one in our `messages` list, it will get overwritten!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6f82fd-a5a8-4e98-80f6-bb058f2acc47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Hello! How can I assist you?', additional_kwargs={}, response_metadata={}, name='Model', id='1'),\n",
       " HumanMessage(content=\"I'm looking for information on whales, specifically\", additional_kwargs={}, response_metadata={}, name='Lance', id='2')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial state\n",
    "initial_messages = [AIMessage(content=\"Hello! How can I assist you?\", name=\"Model\", id=\"1\"),\n",
    "                    HumanMessage(content=\"I'm looking for information on marine biology.\", name=\"Lance\", id=\"2\")\n",
    "                   ]\n",
    "\n",
    "# New message to add\n",
    "# This will overwrite the previous HumanMessage, as the id is the same\n",
    "new_message = HumanMessage(content=\"I'm looking for information on whales, specifically\", name=\"Lance\", id=\"2\")\n",
    "\n",
    "# Test\n",
    "add_messages(initial_messages , new_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06e7788-7054-4752-99fe-27ebb901f263",
   "metadata": {},
   "source": [
    "### Removal\n",
    "\n",
    "`add_messages` also [enables message removal](https://langchain-ai.github.io/langgraph/how-tos/memory/delete-messages/). \n",
    "\n",
    "For this, we simply use [RemoveMessage](https://api.python.langchain.com/en/latest/messages/langchain_core.messages.modifier.RemoveMessage.html) from `langchain_core`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ac97e5-efe2-40bc-9fe3-fd4f50922b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RemoveMessage(content='', additional_kwargs={}, response_metadata={}, id='1'), RemoveMessage(content='', additional_kwargs={}, response_metadata={}, id='2')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import RemoveMessage\n",
    "\n",
    "# Message list\n",
    "messages = [AIMessage(\"Hi.\", name=\"Bot\", id=\"1\")]\n",
    "messages.append(HumanMessage(\"Hi.\", name=\"Lance\", id=\"2\"))\n",
    "messages.append(AIMessage(\"So you said you were researching ocean mammals?\", name=\"Bot\", id=\"3\"))\n",
    "messages.append(HumanMessage(\"Yes, I know about whales. But what others should I learn about?\", name=\"Lance\", id=\"4\"))\n",
    "\n",
    "# Delete messages by id\n",
    "# Slices the message list in order to delete all messages except the last two\n",
    "delete_messages = [RemoveMessage(id=m.id) for m in messages[:-2]]\n",
    "print(delete_messages) # shows that when executed, the messages with id \"1\" and \"2\" will be deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d250578-3ec0-452e-91c0-072d785d96db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='So you said you were researching ocean mammals?', additional_kwargs={}, response_metadata={}, name='Bot', id='3'),\n",
       " HumanMessage(content='Yes, I know about whales. But what others should I learn about?', additional_kwargs={}, response_metadata={}, name='Lance', id='4')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Executing the reducer, passing the messagens and the ones to delete.\n",
    "add_messages(messages , delete_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db095c5-6d9a-4e62-a097-0403797511f6",
   "metadata": {},
   "source": [
    "We can see that mesage IDs 1 and 2, as noted in `delete_messages` are removed by the reducer.\n",
    "\n",
    "We'll see this put into practice a bit later."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc-academy-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
