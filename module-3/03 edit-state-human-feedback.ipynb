{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "147e576c",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-3/edit-state-human-feedback.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239520-lesson-3-editing-state-and-human-feedback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2f2448-21c3-4196-9e61-0b47e7d0048b",
   "metadata": {},
   "source": [
    "# Editing graph state\n",
    "\n",
    "## Review\n",
    "\n",
    "We discussed motivations for human-in-the-loop:\n",
    "\n",
    "(1) `Approval` - We can interrupt our agent, surface state to a user, and allow the user to accept an action\n",
    "\n",
    "(2) `Debugging` - We can rewind the graph to reproduce or avoid issues\n",
    "\n",
    "(3) `Editing` - You can modify the state \n",
    "\n",
    "We showed how breakpoints support user approval, but don't yet know how to modify our graph state once our graph is interrupted!\n",
    "\n",
    "## Goals\n",
    "\n",
    "Now, let's show **how to directly edit the graph state and insert human feedback**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95d26b8c-d958-4d21-9ca4-4636d3dfe45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langgraph langchain_openai langgraph_sdk langgraph-prebuilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5948594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a8df1f-a76a-4803-a532-ea9802106ac8",
   "metadata": {},
   "source": [
    "## Editing state \n",
    "\n",
    "Previously, we introduced breakpoints.\n",
    "\n",
    "We used them to interrupt the graph and await user approval before executing the next node.\n",
    "\n",
    "#### But breakpoints are also [opportunities to modify the graph state](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/edit-graph-state/).\n",
    "\n",
    "Let's set up our agent with a breakpoint before the `assistant` node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcf24f05-ac2b-455e-846c-0c50ac86e1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Define the tools\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "def divide(a: int, b: int) -> float:\n",
    "    \"\"\"Divide a by b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a / b\n",
    "\n",
    "tools = [add, multiply, divide]\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dfe84af-5c62-4c3f-8ed7-96b5261f0b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.prebuilt import tools_condition, ToolNode\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# System message\n",
    "sys_msg = SystemMessage(content=\"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\")\n",
    "\n",
    "# Node\n",
    "def assistant(state: MessagesState):\n",
    "   return {\"messages\": [llm_with_tools.invoke([sys_msg] + state[\"messages\"])]}\n",
    "\n",
    "# Graph\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Define nodes: these do the work\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "# Define edges: these determine the control flow\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "# COmpile graph with interrupt before ASSISTANT\n",
    "# This will interrupt the graph execution before the assistant node\n",
    "graph = builder.compile(interrupt_before=[\"assistant\"], checkpointer=memory)\n",
    "\n",
    "# Show\n",
    "display(Image(graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a47fd5-1f60-41dc-9206-698ed8ece530",
   "metadata": {},
   "source": [
    "Let's run!\n",
    "\n",
    "We can see the graph is interrupted before the chat model responds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2ce488d-00e4-492e-a62c-dd98702c313f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 2 and 3\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "initial_input = {\"messages\": \"Multiply 2 and 3\"}\n",
    "\n",
    "# Thread\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Run the graph until the first interruption\n",
    "for event in graph.stream(initial_input, thread, stream_mode=\"values\"):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4be478ef-bd60-4d32-8a05-5f56c93a8396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='Multiply 2 and 3', additional_kwargs={}, response_metadata={}, id='58637d16-ec44-44ff-978b-6d245ad92445')]}, next=('assistant',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f09add2-fa15-61b4-8000-faaa7277efda'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-09-26T13:32:02.603648+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f09add2-fa10-6b7d-bfff-4236b31834d4'}}, tasks=(PregelTask(id='ac116895-2f85-7072-a4f9-45fa3eff9bf7', name='assistant', path=('__pregel_pull', 'assistant'), error=None, interrupts=(), state=None, result=None),), interrupts=())"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = graph.get_state(thread)\n",
    "state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ef63a1-2ab8-416d-babf-d35054e294f0",
   "metadata": {},
   "source": [
    "Now, we can directly apply a state update.\n",
    "\n",
    "Remember, **updates to the `messages` key will use the `add_messages` reducer**:\n",
    " \n",
    "* If we want to over-write the existing message, we can supply the message `id`.\n",
    "* If we simply want to append to our list of messages, then we can pass a message **without an `id` specified**, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9179cff1-e529-473a-9ce2-e23b932c2063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f09add6-2a42-63ea-8001-ec8540560986'}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.update_state(\n",
    "    thread, # same thread id\n",
    "    {\"messages\": [HumanMessage(content=\"No, actually multiply 3 and 3!\")]},\n",
    ")\n",
    "# No message id specified = append new message to the end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77b8d6a-8c7b-4f7a-b723-121af25ac829",
   "metadata": {},
   "source": [
    "Let's have a look.\n",
    "\n",
    "We called `update_state` with a new message. \n",
    "\n",
    "The `add_messages` reducer appends it to our state key, `messages`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "141b6aab-ec6d-44f3-beb1-6c22ac5f2158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 2 and 3\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "No, actually multiply 3 and 3!\n"
     ]
    }
   ],
   "source": [
    "new_state = graph.get_state(thread).values\n",
    "for m in new_state['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4041959-cc3a-4168-8cf7-06d1711921d8",
   "metadata": {},
   "source": [
    "Now, let's proceed with our agent, simply by passing `None` and allowing it proceed from the current state.\n",
    "\n",
    "We emit the current and then proceed to execute the remaining nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f166bed2-87c9-41ec-b235-0305721c2d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "No, actually multiply 3 and 3!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_Byr9JlLuhf03gmiDAtxVA2F0)\n",
      " Call ID: call_Byr9JlLuhf03gmiDAtxVA2F0\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 3\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for event in graph.stream(None, thread, stream_mode=\"values\"): # passing None to proceed from the current state\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18dc1ca",
   "metadata": {},
   "source": [
    "Now, we're back at the `assistant`, **which has our `breakpoint`**.\n",
    "\n",
    "We can **again pass `None` to proceed**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5952731-0170-4589-a399-ee787df35400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "9\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of multiplying 3 and 3 is 9.\n"
     ]
    }
   ],
   "source": [
    "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc22c3e9-b00c-4ead-b752-a682b45b3718",
   "metadata": {},
   "source": [
    "### Editing graph state in Studio\n",
    "\n",
    "**⚠️ DISCLAIMER**\n",
    "\n",
    "Since the filming of these videos, we've updated Studio so that it can be run locally and opened in your browser. This is now the preferred way to run Studio (rather than using the Desktop App as shown in the video). See documentation [here](https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/#local-development-server) on the local development server and [here](https://langchain-ai.github.io/langgraph/how-tos/local-studio/#run-the-development-server). To start the local development server, run the following command in your terminal in the `/studio` directory in this module:\n",
    "\n",
    "```\n",
    "langgraph dev\n",
    "```\n",
    "\n",
    "You should see the following output:\n",
    "```\n",
    "- 🚀 API: http://127.0.0.1:2024\n",
    "- 🎨 Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024\n",
    "- 📚 API Docs: http://127.0.0.1:2024/docs\n",
    "```\n",
    "\n",
    "Open your browser and navigate to the Studio UI: `https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024`.\n",
    "\n",
    "The LangGraph API [supports editing graph state](https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_edit_state/#initial-invocation). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "020efeba-fa80-4839-81f9-9ce228f9844e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    raise Exception(\"Unfortunately LangGraph Studio is currently not supported on Google Colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "642aabab-f822-4917-9d66-3314ac5008fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the URL of the local development server\n",
    "from langgraph_sdk import get_client\n",
    "client = get_client(url=\"http://127.0.0.1:2024\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be74cb09",
   "metadata": {},
   "source": [
    "Our agent is defined in `studio/agent.py`. \n",
    "\n",
    "If you look at the code, you'll see that it *does not* have a breakpoint! \n",
    " \n",
    "#### Of course, we can add it to `agent.py`, but one very nice feature of the API is that we can pass in a breakpoint!\n",
    "\n",
    "Here, we pass a `interrupt_before=[\"assistant\"]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c352f9e-6a0f-4a94-a083-b85b0233efa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Receiving new event of type: metadata...\n",
      "--------------------------------------------------\n",
      "Receiving new event of type: values...\n",
      "{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': 'd4e882fe-9dd3-4e2b-ba94-133239312c49', 'example': False}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "initial_input = {\"messages\": \"Multiply 2 and 3\"}\n",
    "thread = await client.threads.create()\n",
    "async for chunk in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    \"agent\",\n",
    "    input=initial_input,\n",
    "    stream_mode=\"values\",\n",
    "    interrupt_before=[\"assistant\"], # No need to change the agent.py !\n",
    "):\n",
    "    print(f\"Receiving new event of type: {chunk.event}...\")\n",
    "    messages = chunk.data.get('messages', [])\n",
    "    if messages:\n",
    "        print(messages[-1])\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13065dd9-5f43-47d6-ac2a-9dc15c0c54e6",
   "metadata": {},
   "source": [
    "We can get the current state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4da2c464-3e71-496a-badc-671aeee168b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'values': {'messages': [{'content': 'Multiply 2 and 3',\n",
       "    'additional_kwargs': {},\n",
       "    'response_metadata': {},\n",
       "    'type': 'human',\n",
       "    'name': None,\n",
       "    'id': 'd4e882fe-9dd3-4e2b-ba94-133239312c49',\n",
       "    'example': False}]},\n",
       " 'next': ['assistant'],\n",
       " 'tasks': [{'id': 'c172f04b-7ba9-cab9-cece-fcf4a338bfaf',\n",
       "   'name': 'assistant',\n",
       "   'path': ['__pregel_pull', 'assistant'],\n",
       "   'error': None,\n",
       "   'interrupts': [],\n",
       "   'checkpoint': None,\n",
       "   'state': None,\n",
       "   'result': None}],\n",
       " 'metadata': {'langgraph_auth_user': None,\n",
       "  'langgraph_auth_user_id': '',\n",
       "  'langgraph_auth_permissions': [],\n",
       "  'langgraph_request_id': 'e588eafc-a4d9-4231-8b1f-3034c88e7212',\n",
       "  'graph_id': 'agent',\n",
       "  'assistant_id': 'fe096781-5601-53d2-b2f6-0d3403f7e9ca',\n",
       "  'user_id': '',\n",
       "  'created_by': 'system',\n",
       "  'run_attempt': 1,\n",
       "  'langgraph_version': '0.6.7',\n",
       "  'langgraph_api_version': '0.4.20',\n",
       "  'langgraph_plan': 'developer',\n",
       "  'langgraph_host': 'self-hosted',\n",
       "  'langgraph_api_url': 'http://127.0.0.1:2024',\n",
       "  'run_id': '0199863d-b795-74bd-a386-de21b16d8db8',\n",
       "  'thread_id': '86ea2890-e0d7-4538-9af6-2bcca76087bd',\n",
       "  'source': 'loop',\n",
       "  'step': 0,\n",
       "  'parents': {}},\n",
       " 'created_at': '2025-09-26T13:36:56.638000+00:00',\n",
       " 'checkpoint': {'checkpoint_id': '1f09addd-ee36-663c-8000-56cc258757e6',\n",
       "  'thread_id': '86ea2890-e0d7-4538-9af6-2bcca76087bd',\n",
       "  'checkpoint_ns': ''},\n",
       " 'parent_checkpoint': {'checkpoint_id': '1f09addd-ee34-6a83-bfff-7d3bb7d93157',\n",
       "  'thread_id': '86ea2890-e0d7-4538-9af6-2bcca76087bd',\n",
       "  'checkpoint_ns': ''},\n",
       " 'interrupts': [],\n",
       " 'checkpoint_id': '1f09addd-ee36-663c-8000-56cc258757e6',\n",
       " 'parent_checkpoint_id': '1f09addd-ee34-6a83-bfff-7d3bb7d93157'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_state = await client.threads.get_state(thread['thread_id'])\n",
    "current_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4527bbf1-0927-41a6-aeef-d15e32bbbdc3",
   "metadata": {},
   "source": [
    "We can look at the last message in state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801ae2d9-0551-46b8-aee2-82293cee4011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'Multiply 2 and 3',\n",
       " 'additional_kwargs': {},\n",
       " 'response_metadata': {},\n",
       " 'type': 'human',\n",
       " 'name': None,\n",
       " 'id': 'd4e882fe-9dd3-4e2b-ba94-133239312c49',\n",
       " 'example': False}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_message = current_state['values']['messages'][-1]\n",
    "last_message\n",
    "\n",
    "#  HERE WE HAVE THE  MESSAGE ID!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1243c652",
   "metadata": {},
   "source": [
    "the above will get treated as ano other update to the state!\n",
    "it will get passed to the reducer function for the 'messages' key.\n",
    "> Recall: this reducer will use the ID of the message to update it! -> Overwrite!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0581ba8-db3d-474d-9042-b1c7f3461caf",
   "metadata": {},
   "source": [
    "We can edit it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86b12be7-7e4a-40d0-8521-dced7c393c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'No, actually multiply 3 and 3!',\n",
       " 'additional_kwargs': {},\n",
       " 'response_metadata': {},\n",
       " 'type': 'human',\n",
       " 'name': None,\n",
       " 'id': 'd4e882fe-9dd3-4e2b-ba94-133239312c49',\n",
       " 'example': False}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_message['content'] = \"No, actually multiply 3 and 3!\" # This will be the last message now !\n",
    "last_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f84f2c24-f281-4591-90e5-de3a5547c9da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'No, actually multiply 3 and 3!',\n",
       " 'additional_kwargs': {},\n",
       " 'response_metadata': {},\n",
       " 'type': 'human',\n",
       " 'name': None,\n",
       " 'id': 'd4e882fe-9dd3-4e2b-ba94-133239312c49',\n",
       " 'example': False}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7b4280-6ae7-4246-9c87-44e0daa6c654",
   "metadata": {},
   "source": [
    "Remember, as we said before, **updates to the `messages` key will use the same `add_messages` reducer.**\n",
    "\n",
    "#### If we want to over-write the existing message, then we can supply the message `id`.\n",
    "\n",
    "Here, we did that. We only modified the message `content`, as shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84d33b6e-32ff-4eca-8114-345e508f3481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'checkpoint': {'thread_id': '86ea2890-e0d7-4538-9af6-2bcca76087bd',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f09ade3-8ed9-65d0-8001-c3f8769b0dbe'},\n",
       " 'configurable': {'thread_id': '86ea2890-e0d7-4538-9af6-2bcca76087bd',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f09ade3-8ed9-65d0-8001-c3f8769b0dbe'},\n",
       " 'checkpoint_id': '1f09ade3-8ed9-65d0-8001-c3f8769b0dbe'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await client.threads.update_state(thread['thread_id'], {\"messages\": last_message})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f07f0d1-7083-4827-babd-d3702eb59a37",
   "metadata": {},
   "source": [
    "Now, we resume by passing `None`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef18d12d-e0a6-487a-9f32-ad30e2634a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Receiving new event of type: metadata...\n",
      "--------------------------------------------------\n",
      "Receiving new event of type: values...\n",
      "{'content': 'No, actually multiply 3 and 3!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': 'd4e882fe-9dd3-4e2b-ba94-133239312c49', 'example': False}\n",
      "--------------------------------------------------\n",
      "Receiving new event of type: values...\n",
      "{'content': '', 'additional_kwargs': {'tool_calls': [{'id': 'call_WmE9y5w7kQ3jzFLYPOrw1iay', 'function': {'arguments': '{\"a\":3,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, 'response_metadata': {'token_usage': {'completion_tokens': 17, 'prompt_tokens': 138, 'total_tokens': 155, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CK2yjAkgKwAzZyBIBtHu9w69dnem5', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, 'type': 'ai', 'name': None, 'id': 'run--7e32ae3a-c929-4547-a011-03c63523fd66-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 3, 'b': 3}, 'id': 'call_WmE9y5w7kQ3jzFLYPOrw1iay', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 138, 'output_tokens': 17, 'total_tokens': 155, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}}\n",
      "--------------------------------------------------\n",
      "Receiving new event of type: values...\n",
      "{'content': '9', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': 'bb3578c1-b297-493a-b637-f777b921b83b', 'tool_call_id': 'call_WmE9y5w7kQ3jzFLYPOrw1iay', 'artifact': None, 'status': 'success'}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "async for chunk in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    assistant_id=\"agent\",\n",
    "    input=None, # to resume the execution from where we left off\n",
    "    stream_mode=\"values\",\n",
    "    interrupt_before=[\"assistant\"],\n",
    "):\n",
    "    print(f\"Receiving new event of type: {chunk.event}...\")\n",
    "    messages = chunk.data.get('messages', [])\n",
    "    if messages:\n",
    "        print(messages[-1])\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a82dd35-cbc8-486d-8e20-10d0c4d138d6",
   "metadata": {},
   "source": [
    "We get the result of the tool call as `9`, as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d1bb3c7-dc26-4c32-b3df-865f41ef3c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Receiving new event of type: metadata...\n",
      "--------------------------------------------------\n",
      "Receiving new event of type: values...\n",
      "{'content': '9', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': 'bb3578c1-b297-493a-b637-f777b921b83b', 'tool_call_id': 'call_WmE9y5w7kQ3jzFLYPOrw1iay', 'artifact': None, 'status': 'success'}\n",
      "--------------------------------------------------\n",
      "Receiving new event of type: values...\n",
      "{'content': 'The result of multiplying 3 and 3 is 9.', 'additional_kwargs': {'refusal': None}, 'response_metadata': {'token_usage': {'completion_tokens': 14, 'prompt_tokens': 163, 'total_tokens': 177, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CK2yyFdzc7nJGgCwqpac8sYtVbl8X', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, 'type': 'ai', 'name': None, 'id': 'run--dd8ebda2-730d-4297-9cbb-18bc363b1a0e-0', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 163, 'output_tokens': 14, 'total_tokens': 177, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "async for chunk in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    assistant_id=\"agent\",\n",
    "    input=None,\n",
    "    stream_mode=\"values\",\n",
    "    interrupt_before=[\"assistant\"],\n",
    "):\n",
    "    print(f\"Receiving new event of type: {chunk.event}...\")\n",
    "    messages = chunk.data.get('messages', [])\n",
    "    if messages:\n",
    "        print(messages[-1])\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6914c5ca-27e4-421c-835a-9e4327dac12f",
   "metadata": {},
   "source": [
    "## Awaiting user input\n",
    "\n",
    "So, it's clear that we can edit our agent state after a breakpoint.\n",
    "\n",
    "Now, what if we want to **allow for human feedback to perform this state update**?\n",
    "\n",
    "##### We'll add a node that [serves as a placeholder for human feedback](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/wait-user-input/#setup) within our agent.\n",
    "\n",
    "#### This `human_feedback` node allow the user to add feedback directly to state.\n",
    " \n",
    "> We specify the breakpoint using `interrupt_before` our `human_feedback` node.\n",
    "\n",
    "> We set up a checkpointer to save the state of the graph up until this node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b475ff-681f-4660-80dd-d6ade7bd48e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System message\n",
    "sys_msg = SystemMessage(content=\"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\")\n",
    "\n",
    "# dummy node - no-op (no operation) node that should be interrupted on\n",
    "def human_feedback(state: MessagesState):\n",
    "    pass # no operation!\n",
    "\n",
    "# Assistant node\n",
    "def assistant(state: MessagesState):\n",
    "   return {\"messages\": [llm_with_tools.invoke([sys_msg] + state[\"messages\"])]}\n",
    "\n",
    "# Graph\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Define nodes: these do the work\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "builder.add_node(\"human_feedback\", human_feedback)\n",
    "\n",
    "# Define edges: these determine the control flow\n",
    "builder.add_edge(START, \"human_feedback\")\n",
    "builder.add_edge(\"human_feedback\", \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"human_feedback\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(interrupt_before=[\"human_feedback\"], checkpointer=memory)\n",
    "\n",
    "# Getting error from mermaid API - skipping this step so \n",
    "#display(Image(graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d4ceb6-a224-4307-8196-3f53d367df5c",
   "metadata": {},
   "source": [
    "### We will get feedback from the user.\n",
    "\n",
    "#### We use `.update_state` to update the state of the graph with the human response we get, as before.\n",
    "\n",
    "#### We use the **`as_node=\"human_feedback\"` parameter to apply this state update as the specified node, `human_feedback`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3fc7bcd6-660c-4a8a-ad8d-e6698dcf6201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 2 and 3\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "the capital of rio de janeiro is...?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The capital of the state of Rio de Janeiro is the city of Rio de Janeiro itself.\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "initial_input = {\"messages\": \"Multiply 2 and 3\"}\n",
    "\n",
    "# Define the Thread\n",
    "thread = {\"configurable\": {\"thread_id\": \"5\"}}\n",
    "\n",
    "# Run the graph until the first interruption\n",
    "for event in graph.stream(initial_input, thread, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()\n",
    "    \n",
    "# Get user input\n",
    "user_input = input(\"Tell me how you want to update the state: \") # 7 x 2? ; the capital of rio de janeiro is...?\n",
    "\n",
    "# We now update the state as if we are the human_feedback node\n",
    "graph.update_state(thread, {\"messages\": user_input}, as_node=\"human_feedback\")\n",
    "\n",
    "# Continue the graph execution (pass None as input)\n",
    "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "abf4cf5f-c0cb-4fdb-be6b-271ae4e967e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The capital of the state of Rio de Janeiro is the city of Rio de Janeiro itself.\n"
     ]
    }
   ],
   "source": [
    "# Continue the graph execution\n",
    "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc-academy-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
